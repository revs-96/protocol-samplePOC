# Clinical PDF Data Extraction Platform

## Overview

A professional web application for extracting, analyzing, and visualizing clinical trial data from PDF documents. The platform combines AI-powered OCR capabilities with advanced analytics to transform complex medical PDFs into structured, searchable data tables. Built for precision and efficiency in handling clinical study documents.

**Core Value Proposition**: Automated extraction of tabular data from clinical PDFs (both vector-based and scanned documents) with built-in analytics, visualization, and export capabilities.

## User Preferences

Preferred communication style: Simple, everyday language.

## System Architecture

### Frontend Architecture

**Framework**: React 18 with TypeScript, built using Vite as the build tool and development server.

**UI Component System**: Shadcn UI (Radix UI primitives) + Tailwind CSS
- **Rationale**: Professional, accessible components suitable for enterprise data applications. Provides clean, trustworthy aesthetic appropriate for medical/clinical contexts.
- **Design Philosophy**: Data-first approach prioritizing information clarity over decoration, WCAG AA accessibility compliance.
- **Styling Strategy**: Tailwind utility classes with custom design tokens for medical aesthetic. Typography uses Inter for UI/data and JetBrains Mono for monospace content.

**State Management**: TanStack Query (React Query) for server state management
- **Rationale**: Handles data fetching, caching, and synchronization without additional global state libraries.
- **Configuration**: Infinite stale time, no automatic refetching (user-controlled data updates).

**Routing**: Wouter (lightweight React router)
- **Key Routes**: Landing page, Dashboard, Upload, Tables view, Analytics, Export functionality.

**Key Pages**:
- **Landing**: Marketing/introduction page
- **Dashboard**: Overview statistics (total extractions, success/failure counts, recent uploads)
- **Upload**: Drag-and-drop PDF upload with progress tracking
- **Tables**: View and search extracted tabular data
- **Analytics**: Visualizations using Recharts (bar charts, frequency analysis)
- **Export**: Download extracted data as CSV, Excel, or JSON

### Backend Architecture

**Hybrid Architecture**: Node.js (Express) + Python (FastAPI)

**Node.js Server (Express)**:
- Primary application server handling frontend serving, routing, and proxying
- **Port**: Production deployment handles both static assets and API routing
- **Key Responsibilities**:
  - Vite dev server integration in development mode
  - Static file serving in production
  - Request logging middleware
  - File upload handling (multer for multipart form data)
  - Proxying PDF processing requests to Python backend

**Python Server (FastAPI)**:
- **Port**: 8000
- **Purpose**: CPU-intensive PDF processing and OCR operations
- **Spawned Process**: Node.js spawns Python server as child process on startup
- **Key Responsibilities**:
  - PDF table extraction using Camelot (vector PDFs)
  - OCR processing using Groq API with Mistral models (scanned PDFs)
  - Table stitching across multiple pages
  - Data normalization and cleanup
  - Analytics computation

**Processing Strategy**:
1. Detect if PDF is vector-based (Camelot can parse) or requires OCR
2. Vector PDFs: Use Camelot with both "lattice" and "stream" flavors
3. Scanned PDFs: Convert to images, process with Groq Vision API
4. Post-processing: Stitch multi-page tables, normalize headers, clean null values
5. Analytics generation: Visit frequency analysis, period analysis, summary statistics

### Data Storage

**Current Implementation**: In-memory storage (MemStorage class)
- **Structure**: Map-based storage with UUID keys
- **Data Model**: PdfExtraction records containing filename, upload timestamp, processing status, extracted data, analytics data, and error messages

**Database Schema Preparation**: Drizzle ORM with PostgreSQL schema defined
- **Table**: `pdf_extractions` with JSONB columns for flexible data storage
- **Migration Ready**: Schema and Drizzle config present but not currently connected
- **Future Integration**: Application structured to swap MemStorage for database-backed storage without API changes

**Key Design Decision**: 
- **Problem**: Need flexible storage for variable table structures
- **Solution**: JSONB columns for `extractedData` and `analyticsData`
- **Rationale**: Clinical tables vary significantly in structure; JSONB provides flexibility while maintaining queryability

### API Design

**RESTful Endpoints**:
- `POST /api/upload` - Upload PDF file, returns extraction ID
- `GET /api/extractions` - List all extractions
- `GET /api/extractions/:id` - Get specific extraction with data
- `GET /api/dashboard` - Dashboard statistics
- `GET /api/export/:id?format=csv|excel|json` - Download extracted data

**Data Flow**:
1. Frontend uploads PDF via multipart form data
2. Express receives file, creates extraction record (status: "processing")
3. Express forwards file to Python FastAPI server
4. Python processes PDF asynchronously, returns results
5. Express updates extraction record with results or error
6. Frontend polls/refetches to get updated status

## External Dependencies

### Third-Party Services

**Groq API**: AI-powered OCR for scanned PDFs
- **Purpose**: Vision model (Mistral) for extracting tables from PDF images
- **Configuration**: Requires `GROQ_API_KEY` environment variable
- **Usage Pattern**: Convert PDF pages to base64 images, send to Groq for structured table extraction

### Database

**Neon Database** (PostgreSQL via @neondatabase/serverless)
- **Current Status**: Schema defined, not actively used (in-memory storage active)
- **Connection**: Expects `DATABASE_URL` environment variable
- **ORM**: Drizzle ORM for type-safe database operations
- **Session Storage**: `connect-pg-simple` for PostgreSQL session storage (prepared but not implemented)

### Python Libraries

**Core Processing**:
- **pdf2image**: Convert PDF pages to images for OCR path
- **camelot-py**: Extract tables from vector-based PDFs
- **PyPDF2**: PDF manipulation utilities
- **pandas**: Data manipulation and table operations
- **numpy**: Numerical operations for data processing

**API Framework**:
- **FastAPI**: Python web framework for processing API
- **uvicorn**: ASGI server for FastAPI

**External APIs**:
- **Groq Python SDK**: Interface to Groq Vision API

### Frontend Libraries

**UI Components**: Complete Radix UI ecosystem (@radix-ui/react-*)
- Accessible primitives for dialogs, dropdowns, tooltips, navigation, etc.

**Data Visualization**: Recharts for clinical data charts

**Form Handling**: React Hook Form with Zod validation (@hookform/resolvers)

**File Upload**: react-dropzone for drag-and-drop PDF uploads

**Utilities**:
- date-fns: Date formatting and manipulation
- clsx + tailwind-merge: Conditional CSS class management
- class-variance-authority: Component variant system

### Build Tools

**Vite**: Build tool and dev server with React plugin

**TypeScript**: Type safety across entire application

**PostCSS**: CSS processing with Tailwind and Autoprefixer

**ESBuild**: Server-side bundling for production

### Development Tools

**Replit-Specific**:
- @replit/vite-plugin-runtime-error-modal: Error overlay
- @replit/vite-plugin-cartographer: Code mapping
- @replit/vite-plugin-dev-banner: Development banner